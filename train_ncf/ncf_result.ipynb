{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ncf_result.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMNkVvDDlciK6y7r7jiYI8o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gjFRajn-ZRD3","executionInfo":{"status":"ok","timestamp":1653530189184,"user_tz":-540,"elapsed":20831,"user":{"displayName":"권송아","userId":"17413402186240137810"}},"outputId":"a2bfbb99-6458-4687-bc0e-ace109ce1639"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"k0m3xp8WBPCe","executionInfo":{"status":"ok","timestamp":1653530195467,"user_tz":-540,"elapsed":6291,"user":{"displayName":"권송아","userId":"17413402186240137810"}}},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import os\n","import sys\n","sys.path.append('/content/drive/MyDrive/(22-1)캡스톤/recomm/Recommendation/')\n","sys.path.append('/content/drive/MyDrive/(22-1)캡스톤/recomm/Recommendation/model/MF')\n","sys.path.append('/content/drive/MyDrive/(22-1)캡스톤/recomm/Recommendation/model/NCF')\n","import Loader\n","import MF\n","from neuralCF import NCF\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["class Result:\n","  def __init__(self, batch_size):\n","    DIR = '/content/drive/MyDrive/(22-1)캡스톤/recomm/data/preprocessed/'\n","    loader1 = Loader.Loader(DIR, 1, 4) \n","    loader2 = Loader.Loader(DIR, 2, 4)\n","    loader3 = Loader.Loader(DIR, 3, 4)\n","    loader4 = Loader.Loader(DIR, 4, 4)\n","    loader5 = Loader.Loader(DIR, 5, 4)\n","    loader1.load_dataset()\n","    loader2.load_dataset()\n","    loader3.load_dataset()\n","    loader4.load_dataset()\n","    loader5.load_dataset()\n","    self.loaders = [loader1, loader2, loader3, loader4, loader5]\n","\n","\n","    DIR2 = '/content/drive/MyDrive/(22-1)캡스톤/recomm/data/raw_data/'\n","    problemMeta = pd.read_csv(os.path.join(DIR2, \"problemMeta.csv\"))\n","    self.probid2level = {row[0]:row[5] for row in problemMeta.values}\n","\n","    #self.mf = MF.MF(loader1.users_no, loader1.prob_no, loader1.useridx2level, loader1.probidx2level)\n","    self.ncf = NCF(loader1.users_no, loader1.prob_no, loader1.useridx2level, loader1.probidx2level)\n","    #BESTMODEL_DIR = '/content/drive/MyDrive/(22-1)캡스톤/recomm/Recommendation/model/MF/best_model/cluster'\n","    BESTMODEL_DIR = '/content/drive/MyDrive/(22-1)캡스톤/recomm/Recommendation/model/NCF/best_model/cluster'\n","    model1 = tf.keras.models.load_model(BESTMODEL_DIR+'1')\n","    model2 = tf.keras.models.load_model(BESTMODEL_DIR+'2')\n","    model3 = tf.keras.models.load_model(BESTMODEL_DIR+'3')\n","    model4 = tf.keras.models.load_model(BESTMODEL_DIR+'4')\n","    model5 = tf.keras.models.load_model(BESTMODEL_DIR+'5')\n","    self.models = [model1, model2, model3, model4, model5]\n","\n","    self.batch_size = batch_size\n","\n","\n","  def get_output(self, id, problemIds):\n","    cluster = self.get_cluster(problemIds)\n","    output = self.goto_model(id, problemIds, self.models[cluster-1], cluster)\n","    return output\n","\n","  def get_cluster(self, problemIds):\n","   maxlevel = max([self.probid2level[prob] for prob in problemIds])\n","   if maxlevel <= 4 and maxlevel >= 1:\n","     return 1\n","   elif maxlevel <= 10:\n","     return 2\n","   elif maxlevel <= 13:\n","     return 3\n","   elif maxlevel <= 16:\n","     return 4\n","   else:\n","     return 5\n","\n","  def goto_model(self, id, problemIds, model, cluster):\n","    usridx = self.get_usr_index(id, cluster)\n","    probidx = self.get_prb_index(problemIds, cluster)\n","    neg_probidx = self.get_negative_prob(probidx, cluster)\n","    \n","    train_usr = np.array([usridx] * len(probidx)).reshape(-1,1)\n","    train_prb = np.array(probidx).reshape(-1,1)\n","    train_entry = np.ones_like(train_usr)\n","\n","    test_usr = np.array([usridx] * len(neg_probidx)).reshape(-1,1)\n","    test_prb = np.array(neg_probidx).reshape(-1,1)\n","\n","    weights = model.get_weights()\n","    for i in range(0, len(train_usr), self.batch_size):\n","      idxlist = range(i, min(i+self.batch_size, len(train_usr)-1))\n","      model.fit([train_usr[idxlist], train_prb[idxlist]], train_entry[idxlist], verbose=0)\n","          \n","    for i in range(0, len(test_usr), self.batch_size):\n","      idxlist = range(i, min(i+self.batch_size, len(test_usr)-1))\n","      pred = model.predict([test_usr[idxlist], test_prb[idxlist]])\n","      pred = np.concatenate(pred).reshape(-1,1)\n","    \n","    filtered = self.ncf.level_filtering(test_usr, test_prb, pred, self.loaders[cluster-1].useridx2level, self.loaders[cluster-1].probidx2level, k=30)\n","    #filtered = self.mf.level_filtering(test_usr, test_prb, pred, self.loaders[cluster-1].useridx2level, self.loaders[cluster-1].probidx2level, k=30)\n","    model.set_weights(weights)\n","\n","    output = self.get_id(filtered[1], cluster)\n","    return output\n","\n","  def get_usr_index(self, id, cluster):\n","    try:\n","      usridx = self.loaders[cluster-1].userid2idx[id]\n","    except:\n","      usridx = self.loaders[cluster-1].users_no + self.loaders[cluster-1].users_free\n","    return usridx\n","  \n","  def get_prb_index(self, problemIds, cluster):\n","    prbidx = [self.loaders[cluster-1].probid2idx[prob] for prob in problemIds]\n","    return prbidx\n","  \n","  def get_negative_prob(self, problems, cluster):\n","    return list(set(range(0, self.loaders[cluster-1].prob_no)) - set(problems))\n","\n","  def get_id(self,problems, cluster):\n","    prbidx = [self.loaders[cluster-1].probidx2id[prob] for prob in problems]\n","    return prbidx"],"metadata":{"id":"iStvnqXBBZEo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import Result\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","result = Result(1024)\n","# id가 없는 경우 기존 아이디랑 겹치지 않게 임의지정해서 실행\n","result.get_output(\"gunjung2147\", [1152, 2562, 1157, 2438, 2439, 11654, 1546, 11021, 11022, 2577, 9498, 2588, 1316, 1065, 1712, 1330, 2739, 2741, 2742, 10809, 10171, 10172, 10430, 15552, 2753, 4673, 10818, 2884, 10950, 10951, 10952, 8393, 11720, 2941, 1110, 14681, 2908, 10718, 1000, 1001, 3052, 15596, 1008, 2675, 2292, 10869, 5622, 10871, 4344, 10998, 2557, 8958])"],"metadata":{"id":"I5zmsc-2YzXn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#\n","result.get_output(\"gunsong2\", [2562, 10757, 1546, 11279, 2577, 2579, 2581, 10773, 11286, 2588, 1065, 2606, 10809, 10816, 2557, 3649, 4673, 10817, 10818, 10828, 1110, 11866, 10845, 2667, 2156, 10866, 2675, 2164, 10869, 10870, 7287, 1655, 10871, 10872, 1149, 1152, 2178, 1157, 9372, 1182, 1697, 1193, 10926, 1712, 2739, 2741, 2742, 2231, 2750, 2751, 10430, 2753, 15552, 10950, 10951, 10952, 8393, 1753, 1260, 10989, 2798, 15596, 2805, 10998, 4344, 8958, 11021, 11022, 2839, 9498, 15649, 15650, 15651, 1316, 15652, 11047, 1330, 9012, 2869, 5430, 2884, 1874, 18258, 4949, 14681, 2908, 4963, 2920, 1912, 2941, 1920, 2438, 1927, 2439, 1929, 9095, 1931, 1932, 11654, 2447, 7569, 17298, 7576, 1966, 1463, 1978, 10171, 10172, 9663, 11720, 11725, 11726, 11729, 5086, 10718, 1000, 1001, 1002, 1003, 3052, 1008, 1010, 1012, 5622, 1021])"],"metadata":{"id":"SValLo0vA8GN"},"execution_count":null,"outputs":[]}]}